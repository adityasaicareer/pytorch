{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the cpu and gpu version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch funcdamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cu111  cuda 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## introduction to tensors\n",
    "## main building block of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multidimentional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.4000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(10.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim\n",
    "#they are tensor domentions not wrt to the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler tensor 0\n",
    "#vector tensor 1\n",
    "#2-d array tensor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENSOR=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above means two 2*3 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets see about the generating the random values of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generally scalers and vectors will be a lower case and matrices and tensors will be the uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random tensors were iportant were important as many neural networks learn from the random numbers and learn grom the data but they \n",
    "start with the random numbers and update them with the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random tensor of size(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "random=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.7392, 0.5589, 0.6181],\n",
       "        [0.4492, 0.5419, 0.6148, 0.6956],\n",
       "        [0.5001, 0.2543, 0.6680, 0.7970]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4450, 0.0009, 0.6842])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrandom=torch.rand(2,10,10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## new random number/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8113, 0.6241, 0.5501, 0.0206, 0.3466, 0.4122, 0.7217, 0.3624,\n",
       "          0.3669, 0.9636],\n",
       "         [0.3845, 0.0542, 0.6254, 0.5909, 0.0060, 0.9730, 0.0107, 0.8296,\n",
       "          0.6259, 0.1710],\n",
       "         [0.4013, 0.3057, 0.0095, 0.1587, 0.2124, 0.9420, 0.4245, 0.3429,\n",
       "          0.0843, 0.2564],\n",
       "         [0.7510, 0.5130, 0.7052, 0.3843, 0.8015, 0.1460, 0.0568, 0.2902,\n",
       "          0.0980, 0.6235],\n",
       "         [0.3071, 0.2254, 0.8541, 0.6745, 0.2818, 0.7908, 0.9260, 0.9994,\n",
       "          0.0544, 0.6151],\n",
       "         [0.9456, 0.5760, 0.0689, 0.5205, 0.1727, 0.2693, 0.4656, 0.8405,\n",
       "          0.1788, 0.5527],\n",
       "         [0.3422, 0.9114, 0.2224, 0.7560, 0.0663, 0.7140, 0.1371, 0.5900,\n",
       "          0.1941, 0.5729],\n",
       "         [0.6433, 0.5100, 0.1587, 0.7665, 0.0201, 0.4102, 0.6691, 0.5972,\n",
       "          0.7379, 0.8478],\n",
       "         [0.6909, 0.7579, 0.1494, 0.2709, 0.8799, 0.7824, 0.6457, 0.4859,\n",
       "          0.8616, 0.9944],\n",
       "         [0.7187, 0.6009, 0.9488, 0.1577, 0.4352, 0.1106, 0.9393, 0.4566,\n",
       "          0.1399, 0.4891]],\n",
       "\n",
       "        [[0.7177, 0.1729, 0.6124, 0.0432, 0.1173, 0.3005, 0.1043, 0.5312,\n",
       "          0.1121, 0.6028],\n",
       "         [0.1544, 0.2365, 0.5098, 0.1888, 0.9406, 0.5611, 0.8953, 0.6154,\n",
       "          0.7438, 0.6330],\n",
       "         [0.2483, 0.8092, 0.4829, 0.1542, 0.1752, 0.3167, 0.9113, 0.7812,\n",
       "          0.2868, 0.9247],\n",
       "         [0.6277, 0.8465, 0.1701, 0.6709, 0.5022, 0.3558, 0.6657, 0.0465,\n",
       "          0.8674, 0.5925],\n",
       "         [0.2511, 0.3773, 0.4399, 0.9037, 0.6880, 0.2426, 0.7428, 0.9155,\n",
       "          0.5402, 0.5420],\n",
       "         [0.3895, 0.2572, 0.2579, 0.5634, 0.9108, 0.1917, 0.0291, 0.0807,\n",
       "          0.6090, 0.4273],\n",
       "         [0.7420, 0.3757, 0.3330, 0.7105, 0.6284, 0.0710, 0.1588, 0.2548,\n",
       "          0.1481, 0.5649],\n",
       "         [0.2121, 0.5057, 0.2547, 0.6418, 0.6611, 0.6567, 0.0931, 0.0518,\n",
       "          0.0619, 0.3206],\n",
       "         [0.5656, 0.1857, 0.4973, 0.6991, 0.9427, 0.6938, 0.0071, 0.3155,\n",
       "          0.6832, 0.3692],\n",
       "         [0.3672, 0.4040, 0.7575, 0.5057, 0.4532, 0.7677, 0.5927, 0.5745,\n",
       "          0.4012, 0.7785]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newrandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=torch.rand(10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2396e-01, 8.3489e-01, 5.0306e-01, 9.7542e-01, 2.7097e-01,\n",
       "          2.8316e-01, 7.0835e-01, 7.7003e-02, 5.1838e-01, 6.5497e-01],\n",
       "         [4.5748e-01, 7.3684e-01, 2.5128e-01, 3.7799e-01, 7.8000e-01,\n",
       "          2.0276e-01, 6.4923e-01, 9.1423e-01, 6.2301e-01, 6.7247e-01],\n",
       "         [7.7083e-01, 7.4396e-03, 6.1630e-01, 2.8687e-02, 8.9397e-01,\n",
       "          8.3030e-01, 4.3604e-01, 2.6965e-01, 4.8504e-01, 7.5181e-01],\n",
       "         [1.6741e-01, 4.0722e-01, 3.9960e-01, 6.2865e-01, 7.4877e-01,\n",
       "          9.8481e-01, 9.0362e-01, 4.7994e-01, 5.3665e-01, 4.1520e-01],\n",
       "         [4.6078e-01, 3.9381e-01, 3.1455e-01, 3.9879e-01, 1.7032e-01,\n",
       "          4.2630e-01, 9.3652e-01, 5.9282e-01, 6.9113e-01, 8.2696e-01],\n",
       "         [6.6676e-01, 6.7601e-01, 9.9467e-01, 1.9094e-01, 2.9048e-01,\n",
       "          7.0236e-01, 9.8775e-01, 9.4957e-01, 6.8479e-02, 8.2607e-01],\n",
       "         [3.3955e-01, 7.6138e-01, 5.3150e-01, 9.9271e-01, 4.4694e-01,\n",
       "          2.5798e-01, 5.0325e-01, 6.4678e-01, 9.3710e-01, 1.6333e-01],\n",
       "         [4.4851e-01, 4.7162e-01, 4.2435e-01, 4.3724e-02, 9.9847e-01,\n",
       "          1.8818e-01, 2.6672e-01, 3.7274e-01, 7.3729e-01, 4.7264e-01],\n",
       "         [2.4399e-02, 3.6617e-01, 4.9478e-01, 3.5779e-01, 9.5216e-01,\n",
       "          7.7945e-01, 1.8420e-01, 6.2237e-01, 3.1304e-01, 6.1555e-02],\n",
       "         [8.7361e-01, 1.7574e-01, 2.9398e-01, 7.7493e-01, 3.7527e-01,\n",
       "          2.6817e-01, 5.7309e-02, 9.1631e-01, 7.5250e-01, 3.0506e-01]],\n",
       "\n",
       "        [[3.1999e-01, 3.5424e-01, 6.9492e-01, 6.7098e-01, 1.8029e-01,\n",
       "          3.3616e-02, 8.8179e-01, 4.6934e-01, 2.1411e-01, 4.1705e-01],\n",
       "         [3.5023e-01, 3.6066e-02, 7.4325e-01, 2.9684e-01, 5.1045e-01,\n",
       "          8.4537e-01, 6.2984e-01, 9.7504e-01, 9.0716e-01, 9.5607e-01],\n",
       "         [4.3269e-01, 8.7799e-01, 4.9173e-01, 1.3123e-01, 6.3027e-02,\n",
       "          3.8686e-01, 8.3926e-01, 8.3454e-01, 8.5753e-01, 9.4311e-01],\n",
       "         [9.0591e-01, 4.2494e-01, 8.0820e-01, 9.0356e-01, 4.9484e-01,\n",
       "          8.0862e-01, 1.6893e-01, 2.1189e-01, 1.2215e-01, 7.8364e-01],\n",
       "         [6.3736e-01, 7.4013e-01, 4.0204e-01, 3.8627e-01, 5.1963e-01,\n",
       "          5.2208e-01, 3.9255e-01, 7.4004e-02, 3.0370e-01, 7.4698e-01],\n",
       "         [5.2086e-01, 3.4040e-01, 3.9366e-01, 6.3300e-01, 5.9120e-01,\n",
       "          4.1090e-01, 4.7856e-01, 5.1252e-02, 5.3093e-01, 3.7965e-01],\n",
       "         [3.0686e-01, 4.8292e-01, 5.4249e-02, 6.3401e-01, 5.6508e-01,\n",
       "          6.8941e-01, 1.4797e-03, 2.1391e-01, 2.4421e-01, 7.6137e-02],\n",
       "         [2.5492e-01, 7.8526e-01, 6.1731e-01, 9.1203e-01, 3.2129e-01,\n",
       "          2.2999e-01, 3.6820e-02, 4.6049e-01, 9.5311e-01, 1.7007e-02],\n",
       "         [2.3320e-01, 1.3243e-01, 7.8756e-01, 9.6909e-01, 1.0768e-01,\n",
       "          8.4597e-01, 4.8111e-01, 2.7604e-01, 9.3646e-01, 2.7158e-01],\n",
       "         [2.8667e-01, 7.1538e-01, 1.4407e-01, 4.4010e-01, 7.2719e-01,\n",
       "          2.9208e-01, 6.4447e-01, 5.2151e-01, 4.2181e-01, 7.2185e-01]],\n",
       "\n",
       "        [[9.1654e-02, 1.0124e-03, 1.5177e-01, 6.1986e-01, 6.2875e-01,\n",
       "          8.0352e-01, 7.9804e-01, 6.8623e-01, 4.1212e-01, 2.0672e-01],\n",
       "         [7.6126e-01, 4.6580e-01, 9.5403e-02, 6.9924e-01, 7.3451e-02,\n",
       "          3.3503e-01, 4.3858e-02, 2.6856e-01, 8.8768e-01, 5.7937e-01],\n",
       "         [8.8176e-01, 9.9335e-01, 3.8399e-01, 4.2922e-01, 4.5582e-01,\n",
       "          9.7001e-01, 3.0642e-01, 6.7753e-01, 7.9634e-01, 1.2573e-01],\n",
       "         [6.2664e-01, 6.1494e-01, 3.6551e-01, 4.3845e-01, 6.7370e-01,\n",
       "          4.6111e-01, 2.7190e-01, 9.7800e-01, 6.6401e-02, 9.8694e-01],\n",
       "         [5.6440e-01, 8.2450e-02, 1.3691e-01, 7.3893e-01, 3.8876e-01,\n",
       "          2.6183e-02, 1.9829e-02, 3.0431e-01, 5.7449e-01, 6.5027e-01],\n",
       "         [4.8116e-01, 3.6880e-01, 7.6799e-01, 2.0950e-01, 8.3066e-01,\n",
       "          6.7108e-01, 7.1405e-01, 8.3034e-01, 5.4655e-01, 6.8646e-01],\n",
       "         [8.7121e-01, 4.6745e-01, 7.6122e-01, 5.5181e-01, 6.8101e-01,\n",
       "          5.8907e-01, 1.4465e-01, 4.3166e-01, 1.4915e-01, 9.0551e-02],\n",
       "         [5.1452e-01, 2.5715e-01, 4.6692e-01, 4.5046e-02, 6.1503e-01,\n",
       "          5.2128e-01, 3.6487e-01, 3.7550e-01, 9.4516e-01, 2.6566e-01],\n",
       "         [6.0048e-01, 6.0532e-01, 6.6747e-01, 9.7665e-01, 7.7528e-01,\n",
       "          8.7740e-01, 3.6190e-01, 2.4387e-01, 5.6659e-01, 5.7718e-01],\n",
       "         [7.4986e-01, 6.3910e-01, 6.9775e-01, 9.9228e-01, 1.2401e-01,\n",
       "          2.5196e-01, 9.2879e-01, 5.9139e-01, 6.1624e-01, 3.6405e-01]],\n",
       "\n",
       "        [[7.6985e-01, 9.6999e-01, 2.1124e-01, 4.1308e-01, 2.0339e-02,\n",
       "          8.5975e-01, 9.7380e-01, 1.1802e-01, 6.2939e-01, 9.5366e-01],\n",
       "         [1.6384e-02, 5.8050e-01, 5.9908e-01, 9.0334e-01, 3.6552e-01,\n",
       "          1.3075e-02, 1.7502e-01, 7.6683e-01, 6.0278e-01, 2.5757e-01],\n",
       "         [9.3028e-01, 7.5527e-01, 9.3752e-01, 5.1923e-01, 3.3056e-01,\n",
       "          1.3079e-01, 5.5024e-02, 2.9338e-01, 3.3288e-02, 3.7523e-01],\n",
       "         [2.9629e-01, 3.7713e-01, 1.1578e-01, 5.3966e-01, 5.9721e-02,\n",
       "          9.5366e-01, 3.3406e-01, 6.1621e-01, 8.2684e-01, 5.0349e-01],\n",
       "         [3.9892e-01, 2.5059e-01, 8.8623e-01, 2.1408e-01, 2.2933e-01,\n",
       "          4.6329e-01, 2.6182e-01, 7.7341e-01, 1.0725e-01, 8.9802e-01],\n",
       "         [5.4922e-01, 4.4623e-01, 9.6293e-01, 7.7372e-01, 7.5496e-01,\n",
       "          8.6562e-01, 8.5643e-01, 1.4330e-01, 5.3994e-01, 3.0440e-01],\n",
       "         [5.5528e-01, 2.5175e-01, 9.3287e-01, 6.6079e-01, 8.9401e-01,\n",
       "          3.6615e-02, 2.5378e-01, 7.4862e-01, 6.0768e-01, 8.0195e-02],\n",
       "         [3.4321e-01, 1.9088e-01, 4.1868e-01, 3.2501e-02, 7.6548e-02,\n",
       "          8.8492e-01, 2.8763e-01, 4.1021e-01, 9.8943e-01, 3.5938e-01],\n",
       "         [7.0913e-01, 6.5038e-02, 3.9866e-01, 2.4979e-01, 4.5918e-01,\n",
       "          2.9542e-02, 8.1485e-01, 1.8901e-01, 6.7483e-01, 6.3231e-01],\n",
       "         [9.2445e-01, 8.6118e-01, 6.5399e-01, 1.5925e-01, 8.4535e-01,\n",
       "          6.0220e-01, 9.9864e-02, 5.1460e-01, 2.2537e-01, 3.1697e-01]],\n",
       "\n",
       "        [[7.4223e-03, 8.4720e-01, 4.3668e-01, 9.0760e-01, 6.7397e-01,\n",
       "          6.3376e-01, 9.3003e-01, 8.9021e-01, 7.7724e-01, 3.5213e-01],\n",
       "         [5.1799e-01, 6.1534e-01, 9.1901e-01, 2.4046e-01, 4.3161e-01,\n",
       "          5.8621e-02, 5.0861e-01, 8.6201e-01, 7.9230e-01, 2.3354e-01],\n",
       "         [4.1599e-02, 3.0245e-01, 7.9891e-01, 4.7705e-01, 4.4576e-01,\n",
       "          4.2173e-02, 5.8310e-01, 9.0937e-01, 4.2424e-01, 9.7565e-01],\n",
       "         [8.1092e-01, 9.3870e-01, 9.3651e-01, 6.4402e-01, 2.3593e-01,\n",
       "          5.8523e-01, 1.8014e-01, 8.8378e-01, 2.5860e-01, 8.4225e-01],\n",
       "         [5.8208e-01, 5.8064e-01, 6.3217e-01, 1.2405e-03, 9.9310e-01,\n",
       "          9.9765e-01, 8.7246e-01, 4.7625e-01, 1.7572e-01, 2.7105e-01],\n",
       "         [5.4048e-01, 4.9784e-03, 5.1193e-01, 4.2694e-01, 7.3703e-01,\n",
       "          8.7570e-01, 2.3438e-01, 5.8005e-01, 9.4476e-02, 9.6975e-01],\n",
       "         [7.3920e-01, 5.6022e-01, 9.5563e-01, 1.6332e-01, 1.7231e-01,\n",
       "          5.2440e-01, 3.0152e-01, 6.9095e-01, 4.6362e-01, 9.2457e-01],\n",
       "         [2.7117e-01, 2.6810e-01, 9.2520e-01, 4.7551e-01, 8.5795e-01,\n",
       "          7.7711e-03, 1.1139e-01, 2.1610e-01, 9.2409e-01, 5.6727e-01],\n",
       "         [8.1672e-01, 3.1580e-01, 6.6260e-01, 5.0447e-01, 1.3501e-01,\n",
       "          5.7875e-02, 8.6149e-01, 2.1756e-01, 8.4766e-02, 4.1046e-01],\n",
       "         [4.6609e-01, 4.5855e-01, 6.4419e-01, 8.0192e-01, 8.4848e-02,\n",
       "          2.0726e-02, 8.2111e-01, 2.1112e-04, 3.5597e-01, 8.8028e-01]],\n",
       "\n",
       "        [[8.1657e-01, 9.4723e-01, 1.9438e-01, 2.8897e-01, 2.4875e-01,\n",
       "          6.7216e-01, 1.4138e-01, 7.0537e-01, 2.3301e-01, 8.2524e-01],\n",
       "         [3.1943e-01, 3.8408e-01, 7.1204e-01, 8.5011e-01, 6.5699e-01,\n",
       "          3.0380e-02, 9.9933e-01, 1.9562e-01, 2.9523e-01, 3.1057e-01],\n",
       "         [1.8167e-01, 8.3133e-01, 9.2777e-01, 7.6471e-01, 1.4281e-01,\n",
       "          6.9615e-01, 7.0982e-02, 4.6348e-01, 4.4946e-01, 6.8996e-01],\n",
       "         [4.0065e-01, 5.5411e-01, 8.5273e-01, 5.2072e-01, 7.2493e-01,\n",
       "          1.0348e-01, 5.7836e-01, 3.7926e-02, 1.5691e-01, 8.2632e-03],\n",
       "         [9.8415e-01, 7.4006e-01, 2.7077e-01, 8.9024e-01, 2.7259e-01,\n",
       "          9.8960e-01, 9.0349e-01, 5.8779e-01, 9.0751e-02, 2.7172e-01],\n",
       "         [5.9346e-01, 3.2777e-01, 1.0933e-01, 1.8946e-01, 1.0648e-01,\n",
       "          7.2314e-01, 2.9195e-01, 2.1128e-01, 4.8431e-01, 3.2932e-02],\n",
       "         [9.3491e-01, 9.2975e-01, 6.1357e-01, 2.2114e-01, 9.9205e-01,\n",
       "          7.6194e-01, 2.4335e-01, 7.3687e-01, 6.5001e-02, 3.2464e-01],\n",
       "         [1.9102e-01, 3.6187e-01, 7.0745e-01, 9.4348e-01, 5.5104e-01,\n",
       "          8.5540e-01, 9.1957e-01, 4.6907e-02, 2.9160e-01, 3.5002e-01],\n",
       "         [7.3781e-01, 3.1092e-01, 2.5873e-01, 7.3061e-01, 2.3034e-01,\n",
       "          5.4258e-01, 3.2892e-01, 5.0664e-02, 9.9743e-02, 1.2010e-01],\n",
       "         [2.0200e-02, 2.2058e-01, 1.3924e-02, 7.1821e-02, 3.5384e-01,\n",
       "          4.8938e-01, 9.7010e-01, 2.5667e-01, 9.7900e-01, 9.3605e-01]],\n",
       "\n",
       "        [[6.4433e-01, 1.0118e-01, 3.5010e-02, 1.5624e-02, 4.9845e-01,\n",
       "          6.0183e-01, 2.6340e-01, 8.6143e-01, 8.5659e-02, 3.2892e-01],\n",
       "         [4.4277e-01, 4.9853e-01, 2.0019e-01, 9.5968e-01, 3.6889e-01,\n",
       "          2.2640e-01, 9.6888e-01, 1.7181e-01, 3.7767e-01, 3.8135e-01],\n",
       "         [5.5714e-01, 7.8670e-01, 9.4581e-01, 4.0728e-01, 8.8475e-02,\n",
       "          8.6489e-01, 6.9672e-01, 7.5309e-01, 5.1655e-01, 6.8634e-02],\n",
       "         [7.4903e-01, 1.0661e-01, 1.0146e-01, 6.2080e-01, 5.0545e-01,\n",
       "          2.7964e-01, 9.5848e-01, 3.8051e-01, 7.9480e-01, 8.2831e-01],\n",
       "         [2.9854e-01, 9.1431e-02, 7.6895e-01, 5.4060e-01, 3.1216e-01,\n",
       "          3.2677e-01, 9.8084e-01, 6.2968e-01, 6.3660e-01, 7.0779e-01],\n",
       "         [9.5884e-01, 9.7940e-01, 1.8723e-01, 3.1336e-01, 5.1204e-01,\n",
       "          1.3228e-01, 5.1625e-01, 2.9000e-02, 4.2254e-01, 6.7516e-01],\n",
       "         [6.5486e-01, 2.7260e-01, 8.6493e-01, 9.9246e-01, 5.4434e-01,\n",
       "          5.2707e-01, 4.6142e-01, 2.8526e-03, 6.1692e-01, 3.8812e-01],\n",
       "         [9.8483e-01, 6.8353e-01, 3.8581e-01, 7.4843e-01, 7.4463e-01,\n",
       "          9.7480e-01, 2.1126e-01, 5.9896e-02, 6.3409e-01, 5.6317e-01],\n",
       "         [6.2458e-01, 1.6807e-01, 8.0887e-01, 9.0558e-01, 9.3471e-02,\n",
       "          3.0624e-01, 3.3110e-01, 8.5214e-01, 5.7745e-02, 3.0045e-01],\n",
       "         [9.6142e-01, 4.2865e-01, 3.2069e-01, 3.4822e-01, 5.5732e-01,\n",
       "          2.6989e-01, 9.6175e-01, 3.1111e-01, 1.7380e-02, 1.8183e-01]],\n",
       "\n",
       "        [[4.7825e-01, 8.5446e-01, 6.6149e-01, 1.7541e-01, 1.7902e-01,\n",
       "          4.9371e-01, 6.3249e-01, 9.8551e-01, 5.4095e-01, 5.7549e-01],\n",
       "         [3.1252e-01, 3.5320e-03, 5.2426e-01, 6.2401e-01, 3.5261e-01,\n",
       "          8.4338e-01, 7.5642e-01, 1.6135e-01, 9.6681e-01, 6.9463e-01],\n",
       "         [1.1613e-02, 8.2362e-01, 8.5099e-02, 6.4418e-01, 5.1214e-01,\n",
       "          9.6441e-01, 3.4545e-01, 9.1910e-01, 5.5217e-01, 6.4432e-01],\n",
       "         [6.9234e-01, 9.1605e-01, 2.3397e-01, 2.5576e-01, 9.1854e-01,\n",
       "          8.6157e-01, 1.2702e-01, 8.3535e-01, 3.3390e-02, 6.9011e-01],\n",
       "         [4.4289e-01, 3.7124e-01, 8.5123e-01, 7.9902e-01, 2.8036e-02,\n",
       "          2.3929e-01, 3.2222e-01, 8.3065e-01, 4.0887e-01, 7.5529e-01],\n",
       "         [7.4561e-01, 8.6949e-01, 6.0254e-01, 7.0450e-01, 5.2477e-01,\n",
       "          6.4783e-01, 3.0076e-01, 4.5743e-01, 4.7764e-01, 5.9130e-01],\n",
       "         [1.2577e-01, 7.0709e-01, 7.9897e-01, 1.1021e-01, 9.1489e-01,\n",
       "          6.5155e-01, 1.0277e-01, 5.3357e-01, 8.3319e-01, 1.5773e-01],\n",
       "         [5.4188e-02, 5.0149e-01, 6.5744e-01, 5.4626e-01, 1.5250e-01,\n",
       "          6.5519e-01, 3.3413e-01, 1.6132e-01, 5.5130e-01, 5.1897e-01],\n",
       "         [1.9621e-01, 2.2879e-01, 7.7685e-01, 8.4990e-01, 8.0562e-01,\n",
       "          3.6850e-01, 3.7284e-01, 5.5299e-02, 8.9651e-01, 5.5767e-01],\n",
       "         [9.3001e-01, 7.7539e-01, 1.9233e-01, 9.8884e-01, 3.4999e-01,\n",
       "          1.9776e-01, 8.9015e-01, 9.2118e-01, 4.4926e-01, 3.8678e-02]],\n",
       "\n",
       "        [[1.4338e-01, 8.7452e-02, 1.1027e-01, 2.6333e-01, 7.8557e-02,\n",
       "          9.9220e-01, 6.3540e-01, 7.2485e-02, 6.6310e-01, 8.6599e-01],\n",
       "         [9.4988e-01, 7.0212e-01, 5.5564e-01, 3.1510e-01, 4.6496e-01,\n",
       "          9.8970e-02, 8.0567e-01, 2.7372e-01, 5.5466e-01, 1.8933e-02],\n",
       "         [6.1162e-01, 9.7871e-01, 9.2964e-01, 6.1290e-01, 1.9534e-01,\n",
       "          3.5279e-02, 7.9374e-01, 6.0867e-01, 4.9530e-02, 6.6174e-01],\n",
       "         [2.1736e-01, 4.2035e-01, 9.3791e-01, 9.2838e-01, 7.6432e-01,\n",
       "          9.2918e-01, 3.0482e-01, 9.6536e-01, 4.4738e-01, 5.9411e-01],\n",
       "         [9.9569e-01, 8.7030e-01, 8.8480e-01, 8.6740e-01, 7.9608e-01,\n",
       "          7.8144e-01, 3.7626e-01, 3.9889e-01, 1.4786e-01, 2.3493e-01],\n",
       "         [4.1156e-01, 3.8665e-01, 6.5236e-02, 8.5573e-01, 9.7816e-01,\n",
       "          5.8861e-01, 3.5115e-01, 2.6591e-01, 5.3346e-01, 8.4512e-01],\n",
       "         [9.8798e-01, 5.0786e-01, 4.9493e-01, 7.8318e-01, 6.1772e-01,\n",
       "          8.7489e-01, 1.4121e-01, 3.0461e-01, 3.4475e-01, 3.9890e-01],\n",
       "         [2.7809e-01, 4.2520e-01, 9.5032e-01, 4.0360e-01, 3.8808e-02,\n",
       "          7.2824e-01, 7.3789e-01, 2.9982e-01, 1.7019e-02, 7.7369e-01],\n",
       "         [8.8675e-01, 8.3313e-01, 5.7054e-01, 5.2801e-01, 5.7779e-01,\n",
       "          3.6326e-01, 1.9099e-01, 1.8760e-01, 3.0936e-01, 8.5614e-02],\n",
       "         [9.0385e-01, 4.3420e-01, 1.2530e-01, 8.8849e-02, 7.4321e-01,\n",
       "          2.2835e-01, 3.6824e-02, 1.1899e-01, 8.1296e-01, 9.0455e-01]],\n",
       "\n",
       "        [[7.3267e-01, 3.8776e-01, 4.6162e-02, 8.1822e-01, 6.0639e-01,\n",
       "          3.1833e-01, 1.8881e-01, 2.4172e-01, 2.8857e-01, 5.7378e-01],\n",
       "         [4.3364e-02, 4.2674e-01, 1.2739e-01, 5.0476e-01, 6.1160e-01,\n",
       "          4.1373e-01, 4.5441e-02, 7.0939e-01, 5.7474e-01, 3.9659e-01],\n",
       "         [2.6089e-01, 6.1417e-01, 3.7810e-02, 1.8548e-01, 8.3811e-01,\n",
       "          1.2979e-01, 3.9711e-02, 5.8541e-01, 4.8906e-01, 9.7511e-01],\n",
       "         [5.2507e-02, 1.1119e-01, 6.5396e-01, 3.6248e-01, 4.2633e-01,\n",
       "          8.2898e-01, 6.1387e-01, 1.1676e-01, 2.3475e-02, 4.7560e-01],\n",
       "         [8.3422e-01, 7.5809e-01, 9.3256e-01, 4.3703e-01, 4.5739e-01,\n",
       "          4.9591e-01, 4.3692e-01, 3.3454e-01, 7.2159e-02, 5.7241e-01],\n",
       "         [5.4960e-01, 4.5254e-01, 6.2558e-02, 8.7909e-01, 2.9438e-01,\n",
       "          8.1081e-01, 6.1483e-01, 8.0826e-01, 9.8865e-01, 1.7308e-01],\n",
       "         [8.9378e-01, 2.2344e-01, 5.9887e-01, 5.6506e-01, 6.0959e-01,\n",
       "          9.2690e-01, 3.7719e-01, 5.5169e-01, 1.6345e-01, 8.6233e-01],\n",
       "         [7.7519e-01, 8.8241e-01, 4.1303e-02, 7.8377e-01, 8.0742e-01,\n",
       "          5.9611e-01, 4.9615e-01, 3.1915e-01, 3.5565e-01, 9.0536e-01],\n",
       "         [4.5228e-01, 7.9483e-01, 2.6283e-01, 2.2488e-01, 5.6454e-02,\n",
       "          1.1723e-01, 8.9255e-01, 6.2617e-01, 9.1261e-01, 4.7302e-01],\n",
       "         [8.2090e-01, 3.9093e-01, 6.2106e-01, 5.5213e-01, 9.5599e-02,\n",
       "          8.6307e-01, 2.5877e-01, 3.1540e-01, 6.3565e-01, 4.8196e-01]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.7392, 0.5589, 0.6181],\n",
       "        [0.4492, 0.5419, 0.6148, 0.6956],\n",
       "        [0.5001, 0.2543, 0.6680, 0.7970]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random tensor similar to image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img=torch.rand(size=(3,224,224))  #colorchannel,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have the color channel wil have the 3rd dimention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random numbers in the pytorch was more important as the neural network were initiated with the random numbers and then updated with respect to the algorithm\n",
    "\n",
    "`torch.rand(size=(z,x,y))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=torch.rand(100,100,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 10000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9437e-01, 8.1747e-01, 9.5298e-01, 9.5147e-01],\n",
       "        [9.1097e-01, 1.0521e-03, 1.8219e-01, 7.4408e-01],\n",
       "        [1.8686e-04, 5.8479e-01, 2.9987e-01, 5.8721e-01]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create the random values in many ways but rand() was most common way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors in a range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran=torch.rand(300,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/q_kqcf711rs2gm0dt1z3kv3w0000gn/T/ipykernel_8139/3470486478.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(1,100,1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,\n",
       "         13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,\n",
       "         25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,  36.,\n",
       "         37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,\n",
       "         49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,  60.,\n",
       "         61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,  72.,\n",
       "         73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,\n",
       "         85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,\n",
       "         97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(1,100,1)\n",
    "# as the range as not available with the pytorch anymore use the arange which is similar to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.arange(1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_ten=torch.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,1000,77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be more specific we can use the folllowing use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
       "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
       "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
       "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
       "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
       "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
       "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
       "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
       "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
       "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
       "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
       "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
       "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
       "        505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518,\n",
       "        519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "        533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n",
       "        547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560,\n",
       "        561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574,\n",
       "        575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,\n",
       "        589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
       "        603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616,\n",
       "        617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
       "        631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644,\n",
       "        645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658,\n",
       "        659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
       "        673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686,\n",
       "        687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700,\n",
       "        701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
       "        715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728,\n",
       "        729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742,\n",
       "        743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756,\n",
       "        757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770,\n",
       "        771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784,\n",
       "        785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798,\n",
       "        799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812,\n",
       "        813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826,\n",
       "        827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840,\n",
       "        841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854,\n",
       "        855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868,\n",
       "        869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882,\n",
       "        883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
       "        897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910,\n",
       "        911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924,\n",
       "        925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938,\n",
       "        939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952,\n",
       "        953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966,\n",
       "        967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980,\n",
       "        981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994,\n",
       "        995, 996, 997, 998, 999])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=1,end=1000,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten=torch.zeros_like(one_to_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=torch.ones_like(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default dtype id float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#float tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "float32=torch.tensor([3.0,2.9,5.6],dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 2.9000, 5.6000])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default datatype was float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "float2=torch.tensor([1.0,2.4,3.9,5],dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 2.4004, 3.9004, 5.0000], dtype=torch.float16)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "int3=torch.tensor([1,2,4.5],dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.tensor([3.0,6.0,9.0],dtype=None,device=None,requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "# we have to define the space how it was stores for better precision and speed\n",
    "# how much detail that a number conisist of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes are the one of the three big errord we may fall while developing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device=\"cpu\" by default but we can set to cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if one tensor on cpu and another on gpu it will throw the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd=torch.tensor([2.0,4.0,6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device will tell about the which device we are running on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires_grad will tell us wether we need to track gradient or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "float2=float32.type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 2.9004, 5.6016], dtype=torch.float16)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems could be expected\n",
    "#### datatypes were not same\n",
    "#### varaibles wee on diffweent device\n",
    "####  different shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
